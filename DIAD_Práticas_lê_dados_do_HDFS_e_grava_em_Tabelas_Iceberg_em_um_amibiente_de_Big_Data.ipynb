{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "znpBGfvek8nA"
      },
      "outputs": [],
      "source": [
        "# /código em Python que lê dados do HDFS e grava em Tabelas Iceberg em um amibiente de Big Data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iceberg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YlEXccXq_YX",
        "outputId": "5309fa03-d06b-48b0-db62-002a4da85e36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iceberg\n",
            "  Downloading iceberg-0.4.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting radical.entk (from iceberg)\n",
            "  Downloading radical.entk-1.33.0.tar.gz (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting radical.utils>=1.12 (from radical.entk->iceberg)\n",
            "  Downloading radical.utils-1.33.0.tar.gz (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.8/159.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting radical.pilot>=1.22 (from radical.entk->iceberg)\n",
            "  Downloading radical.pilot-1.33.0.tar.gz (480 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.5/480.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting radical.saga>=1.12 (from radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading radical.saga-1.33.0.tar.gz (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.8/324.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting radical.gtod (from radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading radical.gtod-1.20.1.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymongo<4 (from radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading pymongo-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.2/516.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting dill (from radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from radical.utils>=1.12->radical.entk->iceberg)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from radical.utils>=1.12->radical.entk->iceberg) (1.0.5)\n",
            "Collecting netifaces (from radical.utils>=1.12->radical.entk->iceberg)\n",
            "  Downloading netifaces-0.11.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ntplib (from radical.utils>=1.12->radical.entk->iceberg)\n",
            "  Downloading ntplib-0.4.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from radical.utils>=1.12->radical.entk->iceberg) (23.2.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from radical.utils>=1.12->radical.entk->iceberg) (2022.10.31)\n",
            "Collecting apache-libcloud (from radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading apache_libcloud-3.7.0-py2.py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parse (from radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg)\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from apache-libcloud->radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->apache-libcloud->radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->apache-libcloud->radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->apache-libcloud->radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->apache-libcloud->radical.saga>=1.12->radical.pilot>=1.22->radical.entk->iceberg) (3.4)\n",
            "Building wheels for collected packages: iceberg, radical.entk, radical.pilot, radical.utils, radical.saga, netifaces, radical.gtod, parse\n",
            "  Building wheel for iceberg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iceberg: filename=iceberg-0.4-py3-none-any.whl size=21193 sha256=f9029463329066bc6f79e0a9d188011b3cd1574db97c1c124cee5bca669f89cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/d0/73/8ee013945a3efeaa57c01a1c20d219081c1d0a266af131bf48\n",
            "  Building wheel for radical.entk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for radical.entk: filename=radical.entk-1.33.0-py3-none-any.whl size=128569 sha256=d1bfc9746447eb82d173aea03e100a2b65a481194b058d330c0bc2348524cc9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/1b/11/47ea904e1bb45dea04387f6debfd39a6088975b4734a62f987\n",
            "  Building wheel for radical.pilot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for radical.pilot: filename=radical.pilot-1.33.0-py3-none-any.whl size=1060044 sha256=12142e8cf3fe95c8b6edbd0eada3240cb0e0a86aa562c86a653a995115716f1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/e9/e4/639af55ee9dea57a510eb0075e863d44225004223f03c17f6a\n",
            "  Building wheel for radical.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for radical.utils: filename=radical.utils-1.33.0-py3-none-any.whl size=347871 sha256=3767864f81111ec7620752ec0f6c0785184db9725a316ba22d266d8d74fec2d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/1b/67/9601838622c6c8000cd6759fd625fa75e2b048d391d5fa0e01\n",
            "  Building wheel for radical.saga (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for radical.saga: filename=radical.saga-1.33.0-py3-none-any.whl size=699886 sha256=be1ee82fad6d29febd3b127d663fef2e77e561e8b2af82e599859f63ed629894\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/06/5e/90ab3a46d2a19f94afce7cbe41841ab624ae3fa516a6edcf93\n",
            "  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netifaces: filename=netifaces-0.11.0-cp310-cp310-linux_x86_64.whl size=40405 sha256=e5969d0325b9d9f1eb245836b95fbd9661430c59259385bd793829b272c1be18\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/65/b3/4c4cc6038b81ff21cc9df69f2b6774f5f52e23d3c275ed15aa\n",
            "  Building wheel for radical.gtod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for radical.gtod: filename=radical.gtod-1.20.1-py3-none-any.whl size=25841 sha256=0871547519fe1b4f7ddd75080f43065182869256dbc62c01a3f3712a7929017d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/8f/12/e3ed9061ed738e90c2a1455d1d921d68daa4a40f9487a619d3\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24570 sha256=a0dcdf8125a5a02af874348fdd83b09b5457b7c3ff0bc053d094ae96a9140a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4b/f0/eaf5a8de646d8676dc25caa01949b9f9d883b8fa2efb435bc3\n",
            "Successfully built iceberg radical.entk radical.pilot radical.utils radical.saga netifaces radical.gtod parse\n",
            "Installing collected packages: parse, ntplib, netifaces, setproctitle, pymongo, dill, colorama, radical.utils, apache-libcloud, radical.saga, radical.gtod, radical.pilot, radical.entk, iceberg\n",
            "Successfully installed apache-libcloud-3.7.0 colorama-0.4.6 dill-0.3.6 iceberg-0.4 netifaces-0.11.0 ntplib-0.4.0 parse-1.19.0 pymongo-3.13.0 radical.entk-1.33.0 radical.gtod-1.20.1 radical.pilot-1.33.0 radical.saga-1.33.0 radical.utils-1.33.0 setproctitle-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FZYtY3gqt6w",
        "outputId": "c62c58e9-00a7-4acb-e22d-56b3ef0ca0a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyarrow import fs\n",
        "from pyarrow.dataset import dataset\n",
        "from pyarrow import Table\n",
        "from pyarrow import schema\n",
        "#from pyarrow import iceberg"
      ],
      "metadata": {
        "id": "wUSG8FR8qxHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando o Cliente do HDFS\n",
        "hdfs = fs.HadoopFileSystem(host='dominio.com.br', port=8020, user='hadoop_user', passwd='senhas_user')"
      ],
      "metadata": {
        "id": "RuG5o4XmtTwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho par aos dados de origemno HDFS\n",
        "source_data_path = '/path/to/source_data'"
      ],
      "metadata": {
        "id": "ZepEAEzltnwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o local de destino no Arquivo ICeberg.\n",
        "iceberg_table_location = 'hdfs:/home/data_lakehouse/INSS/dados_saida/'"
      ],
      "metadata": {
        "id": "yVSRW8VYtzNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando Objeto Iceberg Table\n",
        "iceberg_table = iceberg.Table.load(iceberg_table_location, hdfs=hdfs)"
      ],
      "metadata": {
        "id": "jAlt2ufRuQQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o esquema da tabela Iceberg\n",
        "schema = schema.Schema.from_pandas(df) # Substitua 'df' pelo DataFrame corrente."
      ],
      "metadata": {
        "id": "mBdDpgYjudCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um novo arquivo Iceberg\n",
        "new_file = iceberg_table.new_data_file()"
      ],
      "metadata": {
        "id": "8yOrzXZduptv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar o escritor Iceberg\n",
        "with new_file.new_row_writer() as writer:\n",
        "  # Ler os dados de origem do HDFS\n",
        "  dataset = dataset(source_data_path, format='parquet', filesystem=hdfs)\n",
        "\n",
        "  for batch in dataset.to_batches():\n",
        "    # Converter o lote de dados para o foramto Arrow Table\n",
        "    arrow_table = Table.from_batches([batch], schema=schema)\n",
        "\n",
        "    # Gravar os dados na tabela Iceberg\n",
        "    writer.write_table(arrow_table)"
      ],
      "metadata": {
        "id": "ayCPB12o2e5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionar o novo arquivo à Tabela Iceberg\n",
        "iceberg_table.new_version().add_file(new_file).commit()"
      ],
      "metadata": {
        "id": "uHym_QVWq8wu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}